{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import gzip\n",
    "import shutil\n",
    "import subprocess\n",
    "import xml.etree.cElementTree as ET\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio.SeqIO.QualityIO import FastqGeneralIterator\n",
    "from Bio.Application import AbstractCommandline, _Option, _Switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmd(cmd):\n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n",
    "    stdout, stderr = p.communicate()\n",
    "    returncode = p.returncode\n",
    "    if returncode:\n",
    "        raise subprocess.CalledProcessError(returncode=returncode, cmd=cmd, output=stdout, stderr=stderr)\n",
    "    return stdout, stderr\n",
    "\n",
    "def count_bases(reads):\n",
    "    stdout, stderr = run_cmd(f\"seqtk fqchk -q3 {reads} | grep ALL\")\n",
    "    return int(stdout.decode().split()[1])\n",
    "\n",
    "def parse_genome_size(gsize):\n",
    "    mult = {'G': 1e9, 'M': 1e6, 'K': 1e3}\n",
    "    prog = re.compile('([\\d\\.]+)([GMK])?')\n",
    "    result = prog.fullmatch(gsize)\n",
    "    if result:\n",
    "        return float(result.group(1)) * mult[result.group(2)]\n",
    "    else:\n",
    "        raise ValueError(f\"Couldn't parse {gsize}\")\n",
    "\n",
    "class InputError(Exception):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "\n",
    "class SequenceReadArchive:\n",
    "    def __init__(self, source):\n",
    "        if self.is_exists(source) is False:\n",
    "            raise FileNotFoundError(f'File {source} does not exist.')\n",
    "        if self.is_sra(source) is False:\n",
    "            raise InputError(f'File {source} is not SRA format.')\n",
    "        self.source = source\n",
    "\n",
    "    @staticmethod\n",
    "    def is_exists(source):\n",
    "        return os.access(source, os.F_OK) and os.path.isfile(source)\n",
    "\n",
    "    @staticmethod\n",
    "    def is_sra(source):\n",
    "        with open(source, 'rb') as handle:\n",
    "            header = next(handle)\n",
    "        return header[:8].decode() == 'NCBI.sra'\n",
    "\n",
    "    @property\n",
    "    def layout(self):\n",
    "        cmd = f'sra-stat -x -s -b 1 -e 2 {self.source}'\n",
    "        stdout, stderr = run_cmd(cmd)\n",
    "        nreads = ET.fromstring(stdout).find('Statistics').attrib['nreads']\n",
    "        return nreads\n",
    "    \n",
    "    @property\n",
    "    def total_bases(self):\n",
    "        cmd = f'sra-stat -x -s -b 1 -e 2 {self.source}'\n",
    "        stdout, stderr = run_cmd(cmd)\n",
    "        return sum(int(quality.attrib['count']) for quality in ET.fromstring(stdout).findall('*/Quality'))\n",
    "\n",
    "    def validate(self):\n",
    "        cmd = f'vdb-validate {self.source}'\n",
    "        stdout, stderr = run_cmd(cmd)\n",
    "        return stderr.decode('utf8').strip().endswith('consistent')\n",
    "\n",
    "    def dump_fastq(self, outdir):\n",
    "        cmd = f'fastq-dump --split-files --outdir {outdir} {self.source}'\n",
    "        run_cmd(cmd)\n",
    "\n",
    "SANGER_SCORE_OFFSET = 33\n",
    "q_mapping = {chr(letter): letter - SANGER_SCORE_OFFSET\n",
    "             for letter in range(SANGER_SCORE_OFFSET, 94 + SANGER_SCORE_OFFSET)}\n",
    "\n",
    "\n",
    "def sequences_quality_check(source, q_score=30, proportion=0.8):\n",
    "    handle = gzip.open(source, 'rt')\n",
    "    per_sequence_quality = []\n",
    "    for title_line, seq_string, quality_string in FastqGeneralIterator(handle):\n",
    "        qualities = [q_mapping[letter] for letter in quality_string]\n",
    "        sequence_quality = sum(qualities) / len(qualities)\n",
    "        per_sequence_quality.append(sequence_quality)\n",
    "    handle.close()\n",
    "    hist, bin_edges = np.histogram(per_sequence_quality, bins=range(0, 94))\n",
    "    q_hist = list(zip(hist, bin_edges[:-1]))\n",
    "    return sum(i for i, j in q_hist if j >= q_score)/sum(i for i, j in q_hist) >= proportion\n",
    "\n",
    "ADAPTERS = '/home/chen1i6c04/Tools/shovill/db/trimmomatic.fa'\n",
    "MIN_BQ = 3\n",
    "TRIM_OPT = f\"ILLUMINACLIP:{ADAPTERS}:2:30:10 LEADING:{MIN_BQ} TRAILING:{MIN_BQ} SLIDINGWINDOW:4:20 MINLEN:36 TOPHRED33\"\n",
    "\n",
    "def trimming(input_reads, outdir, threads=2):\n",
    "    output_reads = os.path.join(outdir, 'clean_reads.fq.gz')\n",
    "    cmd = f\"trimmomatic SE -threads {threads} {input_reads} {output_reads} {TRIM_OPT}\"\n",
    "    run_cmd(cmd)\n",
    "    return output_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpadesCommandline(AbstractCommandline):\n",
    "    def __init__(self, cmd='spades.py', **kwargs):\n",
    "        self.parameters = [\n",
    "            _Option(['-1', 'r1'], '', equate=False),\n",
    "            _Option(['-2', 'r2'], '', equate=False),\n",
    "            _Option(['-s', 's'], '', equate=False),\n",
    "            _Option(['-o', 'outdir'], '', equate=False, is_required=True),\n",
    "            _Option(['--tmp-dir', 'tmpdir'], '', equate=False),\n",
    "            _Option(['-t', 'threads'], '', equate=False),\n",
    "            _Switch(['--careful', 'careful'], ''),\n",
    "            _Switch(['--isolate', 'isolate'], ''),\n",
    "            _Switch(['--disable-gzip-output', 'disable_gzip_output'], ''),\n",
    "        ]\n",
    "        AbstractCommandline.__init__(self, cmd, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(sra_file, outdir, gsize, threads):\n",
    "    prefix = os.path.splitext(os.path.basename(sra_file))[0]\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    \n",
    "    sra = SequenceReadArchive(sra_file)\n",
    "    \n",
    "    tmp = TemporaryDirectory(dir=outdir)\n",
    "    tmp_dir = tmp.name\n",
    "    if sra.layout == '1':\n",
    "        sra.dump_fastq(tmp_dir)\n",
    "        single_reads = os.path.join(tmp_dir, prefix + '_1.fastq')\n",
    "    else:\n",
    "        sys.exit(0)\n",
    "    trim_reads = trimming(single_reads, tmp_dir, threads)\n",
    "    if sequences_quality_check(trim_reads) is False:\n",
    "        sys.exit(0)\n",
    "\n",
    "    depth = sra.total_bases/parse_genome_size(gsize)\n",
    "    if depth > 100:\n",
    "        isolate, careful = True, False\n",
    "    else:\n",
    "        isolate, careful = False, True\n",
    "    spades_tmp = TemporaryDirectory(prefix='spades', dir='/dev/shm/')\n",
    "    spades_outdir = spades_tmp.name\n",
    "    logfile = os.path.join(outdir, 'spades.log')\n",
    "    cline = SpadesCommandline(s=trim_reads, outdir=spades_outdir, tmpdir='/dev/shm/', threads=threads,\n",
    "                              careful=careful, isolate=isolate, disable_gzip_output=True)\n",
    "    stdout, stderr = cline()\n",
    "    with open(logfile, 'w') as handle:\n",
    "        handle.write(stdout)\n",
    "    os.rename(os.path.join(spades_outdir, 'contigs.fasta'), os.path.join(outdir, 'spades.fa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = Path('/media/Synology_49/Vibrio_cholerae_SE_SRA')\n",
    "outpath = Path('/media/NGS/SRA_1/NCBI_Vibrio_cholerae_SE_SRA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/chen1i6c04/miniconda3/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    with Pool(4) as p:\n",
    "        try:\n",
    "            for i in dirpath.iterdir():\n",
    "                sra_file = i/(i.name + '.sra')\n",
    "                p.apply_async(worker, (sra_file, outpath/i.name, '4M', 8))\n",
    "            p.close()\n",
    "            p.join()\n",
    "        except:\n",
    "            p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR1944522\n",
      "SRR1944515\n",
      "SRR1944210\n",
      "SRR1944492\n",
      "SRR1944526\n"
     ]
    }
   ],
   "source": [
    "dirpath = Path('/media/NGS/SRA_1/NCBI_Vibrio_cholerae_SE_SRA/SPAdes')\n",
    "outpath = Path('/media/NGS/SRA_1/NCBI_Vibrio_cholerae_SE_SRA/Contigs')\n",
    "\n",
    "for i in dirpath.iterdir():\n",
    "    src_file = i/'spades.fa'\n",
    "    dst_file = outpath/(i.name + '.fa')\n",
    "    try:\n",
    "        shutil.copy(src_file, dst_file)\n",
    "    except:\n",
    "        print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
